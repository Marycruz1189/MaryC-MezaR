{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "a9b83ec4160fc914f5169c2fc0bc9ab1c02e189a457abfa966969b692f6336e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Mary\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from sklearn import model_selection\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the pretrained models\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.dirname\n",
    "src_path = dir(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = src_path + os.sep + \"src\" +  os.sep + \"utils\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path)\n",
    "import folders_tb as fol "
   ]
  },
  {
   "source": [
    "# VGG16"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## X train X Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\train\\\\**\\\\**.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "path_train = src_path + os.sep + \"data\" +  os.sep + \"train\"  +  os.sep + '**'  +  os.sep + '**.jpg'\n",
    "path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fol.make_imag_df(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fol.creat_colum (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_path = src_path + os.sep + \"data\" + os.sep + \"train\"  +  os.sep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = fol.import_imag(path_path, train)"
   ]
  },
  {
   "source": [
    "## X train X Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\test\\\\**\\\\**.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "path_test = src_path + os.sep + \"data\" +  os.sep + \"test\"  +  os.sep + '**'  +  os.sep + '**.jpg'\n",
    "path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fol.make_imag_df(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fol.creat_colum (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_path_2 = src_path + os.sep + \"data\" + os.sep + \"test\"  +  os.sep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     path_train     name          id             img                    path  \\\n",
       "0          test  battery  battery101  battery101.jpg  battery/battery101.jpg   \n",
       "1          test  battery  battery108  battery108.jpg  battery/battery108.jpg   \n",
       "2          test  battery  battery122  battery122.jpg  battery/battery122.jpg   \n",
       "3          test  battery  battery132  battery132.jpg  battery/battery132.jpg   \n",
       "4          test  battery   battery14   battery14.jpg   battery/battery14.jpg   \n",
       "...         ...      ...         ...             ...                     ...   \n",
       "1198       test  plastic  plastic864  plastic864.jpg  plastic/plastic864.jpg   \n",
       "1199       test  plastic   plastic90   plastic90.jpg   plastic/plastic90.jpg   \n",
       "1200       test  plastic   plastic93   plastic93.jpg   plastic/plastic93.jpg   \n",
       "1201       test  plastic   plastic95   plastic95.jpg   plastic/plastic95.jpg   \n",
       "1202       test  plastic   plastic98   plastic98.jpg   plastic/plastic98.jpg   \n",
       "\n",
       "      label                                         nombre_img  \n",
       "0         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "1         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "2         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "3         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "4         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
       "...     ...                                                ...  \n",
       "1198      6  [[[182, 191, 200], [185, 194, 203], [184, 192,...  \n",
       "1199      6  [[[200, 221, 236], [200, 221, 236], [200, 221,...  \n",
       "1200      6  [[[216, 203, 201], [215, 202, 200], [214, 201,...  \n",
       "1201      6  [[[255, 242, 240], [255, 242, 240], [255, 242,...  \n",
       "1202      6  [[[223, 210, 208], [222, 209, 207], [221, 208,...  \n",
       "\n",
       "[1203 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path_train</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n      <th>path</th>\n      <th>label</th>\n      <th>nombre_img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery101</td>\n      <td>battery101.jpg</td>\n      <td>battery/battery101.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery108</td>\n      <td>battery108.jpg</td>\n      <td>battery/battery108.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery122</td>\n      <td>battery122.jpg</td>\n      <td>battery/battery122.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery132</td>\n      <td>battery132.jpg</td>\n      <td>battery/battery132.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery14</td>\n      <td>battery14.jpg</td>\n      <td>battery/battery14.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic864</td>\n      <td>plastic864.jpg</td>\n      <td>plastic/plastic864.jpg</td>\n      <td>6</td>\n      <td>[[[182, 191, 200], [185, 194, 203], [184, 192,...</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic90</td>\n      <td>plastic90.jpg</td>\n      <td>plastic/plastic90.jpg</td>\n      <td>6</td>\n      <td>[[[200, 221, 236], [200, 221, 236], [200, 221,...</td>\n    </tr>\n    <tr>\n      <th>1200</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic93</td>\n      <td>plastic93.jpg</td>\n      <td>plastic/plastic93.jpg</td>\n      <td>6</td>\n      <td>[[[216, 203, 201], [215, 202, 200], [214, 201,...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic95</td>\n      <td>plastic95.jpg</td>\n      <td>plastic/plastic95.jpg</td>\n      <td>6</td>\n      <td>[[[255, 242, 240], [255, 242, 240], [255, 242,...</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic98</td>\n      <td>plastic98.jpg</td>\n      <td>plastic/plastic98.jpg</td>\n      <td>6</td>\n      <td>[[[223, 210, 208], [222, 209, 207], [221, 208,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1203 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "test_set = fol.import_imag(path_path_2, test)\n",
    "test_set"
   ]
  },
  {
   "source": [
    "### DEFINIR X & Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4803, 224, 224, 3)\n(4803,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack(np.array(train_set[\"nombre_img\"]))\n",
    "y_train = np.array(train_set[\"label\"])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1203, 224, 224, 3)\n(1203,)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.stack(np.array(test_set[\"nombre_img\"]))\n",
    "y_test = np.array(test_set[\"label\"])\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "## RESHAPE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4803, 224, 224, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_train = X_train.reshape(4803, 224, 224, 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4803, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y_train = y_train.reshape(4803, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-900:]\n",
    "y_val = y_train[-900:]\n",
    "X_train = X_train[:-900]\n",
    "y_train = y_train[:-900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(1203, 224, 224, 3)\n",
    "y_test = y_test.reshape(1203,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_val)"
   ]
  },
  {
   "source": [
    "### ENTRENAR EL MODELO BASICO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(input_shape = (224, 224, 3),\n",
    "                  include_top=False, \n",
    "                  weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "x0 = layers.Flatten()(base_model.output) \n",
    "x1 = layers.Dense(512, activation='relu')(x0) \n",
    "x2 = layers.Dropout(0.5)(x1)\n",
    "x3 = layers.Dense(7, activation='softmax')(x2)\n",
    "model = tf.keras.models.Model(base_model.input, x3) \n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               12845568  \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 3591      \n=================================================================\nTotal params: 27,563,847\nTrainable params: 12,849,159\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 882s 7s/step - loss: 8.9769 - acc: 0.8219 - val_loss: 68.4768 - val_acc: 0.2078\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 839s 7s/step - loss: 1.4127 - acc: 0.9283 - val_loss: 93.9466 - val_acc: 0.2089\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 834s 7s/step - loss: 1.1306 - acc: 0.9447 - val_loss: 95.3365 - val_acc: 0.2056\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 802s 7s/step - loss: 0.7363 - acc: 0.9618 - val_loss: 88.0542 - val_acc: 0.2056\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 785s 6s/step - loss: 0.7933 - acc: 0.9646 - val_loss: 120.3599 - val_acc: 0.2122\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 809s 7s/step - loss: 0.6700 - acc: 0.9682 - val_loss: 136.9686 - val_acc: 0.2089\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 799s 7s/step - loss: 0.8240 - acc: 0.9662 - val_loss: 125.3274 - val_acc: 0.2133\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 765s 6s/step - loss: 0.9104 - acc: 0.9708 - val_loss: 137.4225 - val_acc: 0.2067\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 768s 6s/step - loss: 0.5687 - acc: 0.9728 - val_loss: 115.7208 - val_acc: 0.1989\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 787s 6s/step - loss: 0.6325 - acc: 0.9754 - val_loss: 131.0993 - val_acc: 0.2167\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10, verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "38/38 [==============================] - 176s 5s/step - loss: 82.5208 - acc: 0.5195\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTest accuracy: 0.5195344686508179 \nLoss: 82.52079010009766\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = path = src_path +  os.sep + \"models\" + os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_save + \"modelvgg16_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}