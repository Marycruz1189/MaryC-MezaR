{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.4 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "a9b83ec4160fc914f5169c2fc0bc9ab1c02e189a457abfa966969b692f6336e9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA998OpF8fQI"
      },
      "source": [
        "***WASTE SORTING***\n",
        "\n",
        "Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWvpW9NJ9e2z"
      },
      "source": [
        "Incorrect waste disposal can create a number of problems for both public administrations (waste of time and resources due to reprocessing) and the environment (contamination). These problems can be avoided with automatic waste sorting. \n",
        "For this reason, this image classifier has been created, in order to know how to classify waste and materials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7I2wrbePGZP"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile as zf\n",
        "import shutil\n",
        "import re\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from random import choice, randrange"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_yMVYGoaEl1"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "from matplotlib.image import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Dropout,Flatten,Dense, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, Sequential,load_model\n",
        "from sklearn import model_selection\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import tensorflow as tf\n",
        "from skimage.io import imread\n",
        "import cv2\n",
        "import re\n",
        "import glob\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Mary\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n  from .collection import imread_collection_wrapper\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY9-WklsaiHh"
      },
      "source": [
        "dir = os.path.dirname\n",
        "src_path = dir(os.path.abspath(''))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OCJjvX7amcB"
      },
      "source": [
        "X TRAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVq1TvrkF_-E"
      },
      "source": [
        "*Descargar datos para X_train e y_train* *texto en cursiva*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "inzVi0M6bJb1",
        "outputId": "6901ad52-b5bc-4a83-d14c-c2f0e0c47c63"
      },
      "source": [
        "path_train = src_path + os.sep + \"data\" +  os.sep + \"train\"  +  os.sep + '**'  +  os.sep + '**.jpg'\n",
        "path_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\train\\\\**\\\\**.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5wqRxwtcNkx",
        "outputId": "860f8810-e648-4c58-aafa-14288e5d15d3"
      },
      "source": [
        "path = Path(os.getcwd())/\"data\"\n",
        "path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WindowsPath('c:/Users/Mary/Desktop/BootCamp/Python/MaryC-MezaR/data_science_bootcamp_2021/Machine_Learning_project/notebooks/data')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def make_imag_df(path):\n",
        "    dictionary = {}\n",
        "    for paths in glob.glob(path):\n",
        "        dictionary.setdefault('conjunto', []).append(paths.split('\\\\')[-3])\n",
        "        dictionary.setdefault('name', []).append(paths.split('\\\\')[-2])\n",
        "        dictionary.setdefault('id', []).append(paths.split('\\\\')[-1][:-4])\n",
        "        dictionary.setdefault('img', []).append(paths.split('\\\\')[-1])\n",
        "        \n",
        "    images = pd.DataFrame(dictionary)\n",
        "    return images\n",
        "\n",
        "train_set = make_imag_df(path_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "p3FRYgKcbr87",
        "outputId": "9798a01d-bc11-4828-9c39-2a62c85bc493"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     conjunto     name          id             img\n",
              "0       train  battery    battery1    battery1.jpg\n",
              "1       train  battery   battery10   battery10.jpg\n",
              "2       train  battery  battery100  battery100.jpg\n",
              "3       train  battery  battery102  battery102.jpg\n",
              "4       train  battery  battery103  battery103.jpg\n",
              "...       ...      ...         ...             ...\n",
              "4798    train  plastic   plastic92   plastic92.jpg\n",
              "4799    train  plastic   plastic94   plastic94.jpg\n",
              "4800    train  plastic   plastic96   plastic96.jpg\n",
              "4801    train  plastic   plastic97   plastic97.jpg\n",
              "4802    train  plastic   plastic99   plastic99.jpg\n",
              "\n",
              "[4803 rows x 4 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conjunto</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery1</td>\n      <td>battery1.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery10</td>\n      <td>battery10.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery100</td>\n      <td>battery100.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery102</td>\n      <td>battery102.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery103</td>\n      <td>battery103.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4798</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic92</td>\n      <td>plastic92.jpg</td>\n    </tr>\n    <tr>\n      <th>4799</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic94</td>\n      <td>plastic94.jpg</td>\n    </tr>\n    <tr>\n      <th>4800</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic96</td>\n      <td>plastic96.jpg</td>\n    </tr>\n    <tr>\n      <th>4801</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic97</td>\n      <td>plastic97.jpg</td>\n    </tr>\n    <tr>\n      <th>4802</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic99</td>\n      <td>plastic99.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>4803 rows Ã— 4 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82m6piFja8K8"
      },
      "source": [
        "#funcion columna\n",
        "def creat_colum (dataframe):\n",
        "    dataframe['path']= dataframe.name + \"/\" + dataframe.img\n",
        "    dataframe['label'] = dataframe['name'].map({'battery': 0, 'biological': 1, 'cardboard': 2, 'glass':3, 'metal':4, 'paper':5, 'plastic':6})\n",
        "\n",
        "    return dataframe"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_r21OLba-q6"
      },
      "source": [
        "train_set = creat_colum (train_set)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8cnwImvBc4a6",
        "outputId": "a4f83be3-0814-46aa-be38-b4bdd65edfdf"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_set' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-1b17ab7df3fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\train\\\\'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# path para importar las imagenes \n",
        "path_path = src_path + os.sep + \"data\" + os.sep + \"train\"  +  os.sep \n",
        "path_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "imagenes = []\n",
        "size = []\n",
        "#width = []\n",
        "\n",
        "for i in train_set.path:\n",
        "    x = path_path + i\n",
        "    imagenes_rs = cv2.imread(x, 1)\n",
        "    imagenes.append(cv2.resize(imagenes_rs, (224, 224)))\n",
        "    size.append(imagenes_rs.shape)\n",
        "    #width.append(np.size(imagenes_rs, 1))\n",
        "    \n",
        "train_set[\"nombre_img\"] = imagenes\n",
        "train_set['size'] = '(224,224)'\n",
        "#train_set[\"size\"] = size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nd =train_set.assign(size=(224,224))\n",
        "\n",
        "train_set['size'] = '(224,224)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     conjunto     name          id             img                    path  \\\n",
              "0       train  battery    battery1    battery1.jpg    battery/battery1.jpg   \n",
              "1       train  battery   battery10   battery10.jpg   battery/battery10.jpg   \n",
              "2       train  battery  battery100  battery100.jpg  battery/battery100.jpg   \n",
              "3       train  battery  battery102  battery102.jpg  battery/battery102.jpg   \n",
              "4       train  battery  battery103  battery103.jpg  battery/battery103.jpg   \n",
              "...       ...      ...         ...             ...                     ...   \n",
              "4798    train  plastic   plastic92   plastic92.jpg   plastic/plastic92.jpg   \n",
              "4799    train  plastic   plastic94   plastic94.jpg   plastic/plastic94.jpg   \n",
              "4800    train  plastic   plastic96   plastic96.jpg   plastic/plastic96.jpg   \n",
              "4801    train  plastic   plastic97   plastic97.jpg   plastic/plastic97.jpg   \n",
              "4802    train  plastic   plastic99   plastic99.jpg   plastic/plastic99.jpg   \n",
              "\n",
              "      label                                         nombre_img       size  \n",
              "0         0  [[[189, 199, 206], [189, 199, 206], [189, 199,...  (224,224)  \n",
              "1         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (224,224)  \n",
              "2         0  [[[151, 155, 165], [148, 153, 162], [152, 157,...  (224,224)  \n",
              "3         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (224,224)  \n",
              "4         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (224,224)  \n",
              "...     ...                                                ...        ...  \n",
              "4798      6  [[[176, 166, 166], [183, 173, 173], [171, 163,...  (224,224)  \n",
              "4799      6  [[[217, 203, 204], [216, 202, 203], [215, 201,...  (224,224)  \n",
              "4800      6  [[[237, 224, 222], [234, 221, 219], [230, 217,...  (224,224)  \n",
              "4801      6  [[[94, 123, 154], [94, 123, 154], [94, 123, 15...  (224,224)  \n",
              "4802      6  [[[235, 220, 218], [234, 219, 217], [233, 218,...  (224,224)  \n",
              "\n",
              "[4803 rows x 8 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conjunto</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n      <th>path</th>\n      <th>label</th>\n      <th>nombre_img</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery1</td>\n      <td>battery1.jpg</td>\n      <td>battery/battery1.jpg</td>\n      <td>0</td>\n      <td>[[[189, 199, 206], [189, 199, 206], [189, 199,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery10</td>\n      <td>battery10.jpg</td>\n      <td>battery/battery10.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery100</td>\n      <td>battery100.jpg</td>\n      <td>battery/battery100.jpg</td>\n      <td>0</td>\n      <td>[[[151, 155, 165], [148, 153, 162], [152, 157,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery102</td>\n      <td>battery102.jpg</td>\n      <td>battery/battery102.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery103</td>\n      <td>battery103.jpg</td>\n      <td>battery/battery103.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4798</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic92</td>\n      <td>plastic92.jpg</td>\n      <td>plastic/plastic92.jpg</td>\n      <td>6</td>\n      <td>[[[176, 166, 166], [183, 173, 173], [171, 163,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>4799</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic94</td>\n      <td>plastic94.jpg</td>\n      <td>plastic/plastic94.jpg</td>\n      <td>6</td>\n      <td>[[[217, 203, 204], [216, 202, 203], [215, 201,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>4800</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic96</td>\n      <td>plastic96.jpg</td>\n      <td>plastic/plastic96.jpg</td>\n      <td>6</td>\n      <td>[[[237, 224, 222], [234, 221, 219], [230, 217,...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>4801</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic97</td>\n      <td>plastic97.jpg</td>\n      <td>plastic/plastic97.jpg</td>\n      <td>6</td>\n      <td>[[[94, 123, 154], [94, 123, 154], [94, 123, 15...</td>\n      <td>(224,224)</td>\n    </tr>\n    <tr>\n      <th>4802</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic99</td>\n      <td>plastic99.jpg</td>\n      <td>plastic/plastic99.jpg</td>\n      <td>6</td>\n      <td>[[[235, 220, 218], [234, 219, 217], [233, 218,...</td>\n      <td>(224,224)</td>\n    </tr>\n  </tbody>\n</table>\n<p>4803 rows Ã— 8 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'battery/battery1.jpg'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-19-ec7351397a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#x = path_path + i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'battery/battery1.jpg'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "size = []\n",
        "\n",
        "for i in train_set.path:\n",
        "    x = Image.open(i)\n",
        "    size.append(im.size)\n",
        "    #x = path_path + i\n",
        "    #imagenes_rs = cv2.imread(x, 1)\n",
        "    #size.append(imagenes_rs.shape)\n",
        "\n",
        "train_set[\"size\"] = size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKCmyT8mdAVY"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     conjunto     name          id             img                    path  \\\n",
              "0       train  battery    battery1    battery1.jpg    battery/battery1.jpg   \n",
              "1       train  battery   battery10   battery10.jpg   battery/battery10.jpg   \n",
              "2       train  battery  battery100  battery100.jpg  battery/battery100.jpg   \n",
              "3       train  battery  battery102  battery102.jpg  battery/battery102.jpg   \n",
              "4       train  battery  battery103  battery103.jpg  battery/battery103.jpg   \n",
              "...       ...      ...         ...             ...                     ...   \n",
              "4798    train  plastic   plastic92   plastic92.jpg   plastic/plastic92.jpg   \n",
              "4799    train  plastic   plastic94   plastic94.jpg   plastic/plastic94.jpg   \n",
              "4800    train  plastic   plastic96   plastic96.jpg   plastic/plastic96.jpg   \n",
              "4801    train  plastic   plastic97   plastic97.jpg   plastic/plastic97.jpg   \n",
              "4802    train  plastic   plastic99   plastic99.jpg   plastic/plastic99.jpg   \n",
              "\n",
              "      label                                         nombre_img           size  \n",
              "0         0  [[[189, 199, 206], [189, 199, 206], [189, 199,...  (180, 280, 3)  \n",
              "1         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (165, 220, 3)  \n",
              "2         0  [[[151, 155, 165], [148, 153, 162], [152, 157,...  (183, 275, 3)  \n",
              "3         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (224, 224, 3)  \n",
              "4         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  (188, 268, 3)  \n",
              "...     ...                                                ...            ...  \n",
              "4798      6  [[[176, 166, 166], [183, 173, 173], [171, 163,...  (384, 512, 3)  \n",
              "4799      6  [[[217, 203, 204], [216, 202, 203], [215, 201,...  (384, 512, 3)  \n",
              "4800      6  [[[237, 224, 222], [234, 221, 219], [230, 217,...  (384, 512, 3)  \n",
              "4801      6  [[[94, 123, 154], [94, 123, 154], [94, 123, 15...  (384, 512, 3)  \n",
              "4802      6  [[[235, 220, 218], [234, 219, 217], [233, 218,...  (384, 512, 3)  \n",
              "\n",
              "[4803 rows x 8 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conjunto</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n      <th>path</th>\n      <th>label</th>\n      <th>nombre_img</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery1</td>\n      <td>battery1.jpg</td>\n      <td>battery/battery1.jpg</td>\n      <td>0</td>\n      <td>[[[189, 199, 206], [189, 199, 206], [189, 199,...</td>\n      <td>(180, 280, 3)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery10</td>\n      <td>battery10.jpg</td>\n      <td>battery/battery10.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(165, 220, 3)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery100</td>\n      <td>battery100.jpg</td>\n      <td>battery/battery100.jpg</td>\n      <td>0</td>\n      <td>[[[151, 155, 165], [148, 153, 162], [152, 157,...</td>\n      <td>(183, 275, 3)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery102</td>\n      <td>battery102.jpg</td>\n      <td>battery/battery102.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(224, 224, 3)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>battery</td>\n      <td>battery103</td>\n      <td>battery103.jpg</td>\n      <td>battery/battery103.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n      <td>(188, 268, 3)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4798</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic92</td>\n      <td>plastic92.jpg</td>\n      <td>plastic/plastic92.jpg</td>\n      <td>6</td>\n      <td>[[[176, 166, 166], [183, 173, 173], [171, 163,...</td>\n      <td>(384, 512, 3)</td>\n    </tr>\n    <tr>\n      <th>4799</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic94</td>\n      <td>plastic94.jpg</td>\n      <td>plastic/plastic94.jpg</td>\n      <td>6</td>\n      <td>[[[217, 203, 204], [216, 202, 203], [215, 201,...</td>\n      <td>(384, 512, 3)</td>\n    </tr>\n    <tr>\n      <th>4800</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic96</td>\n      <td>plastic96.jpg</td>\n      <td>plastic/plastic96.jpg</td>\n      <td>6</td>\n      <td>[[[237, 224, 222], [234, 221, 219], [230, 217,...</td>\n      <td>(384, 512, 3)</td>\n    </tr>\n    <tr>\n      <th>4801</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic97</td>\n      <td>plastic97.jpg</td>\n      <td>plastic/plastic97.jpg</td>\n      <td>6</td>\n      <td>[[[94, 123, 154], [94, 123, 154], [94, 123, 15...</td>\n      <td>(384, 512, 3)</td>\n    </tr>\n    <tr>\n      <th>4802</th>\n      <td>train</td>\n      <td>plastic</td>\n      <td>plastic99</td>\n      <td>plastic99.jpg</td>\n      <td>plastic/plastic99.jpg</td>\n      <td>6</td>\n      <td>[[[235, 220, 218], [234, 219, 217], [233, 218,...</td>\n      <td>(384, 512, 3)</td>\n    </tr>\n  </tbody>\n</table>\n<p>4803 rows Ã— 8 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXUPlzUhGdBV"
      },
      "source": [
        "**X, Y** **TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E-DQHYuGhtl"
      },
      "source": [
        "Descargar imÃ¡genes para X_test e y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVJ4j_cAGrHM"
      },
      "source": [
        "path_test = src_path + os.sep + \"data\" +  os.sep + \"test\"  +  os.sep + '**'  +  os.sep + '**.jpg'\n",
        "path_test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\test\\\\**\\\\**.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjO9GL8hGq6A"
      },
      "source": [
        "\n",
        "test_set = make_imag_df(path_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpLCKgj5GqtS"
      },
      "source": [
        "test_set = creat_colum (test_set)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-QWg9nUSGho"
      },
      "source": [
        "test_set"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     conjunto     name          id             img                    path  \\\n",
              "0        test  battery  battery101  battery101.jpg  battery/battery101.jpg   \n",
              "1        test  battery  battery108  battery108.jpg  battery/battery108.jpg   \n",
              "2        test  battery  battery122  battery122.jpg  battery/battery122.jpg   \n",
              "3        test  battery  battery132  battery132.jpg  battery/battery132.jpg   \n",
              "4        test  battery   battery14   battery14.jpg   battery/battery14.jpg   \n",
              "...       ...      ...         ...             ...                     ...   \n",
              "1198     test  plastic  plastic864  plastic864.jpg  plastic/plastic864.jpg   \n",
              "1199     test  plastic   plastic90   plastic90.jpg   plastic/plastic90.jpg   \n",
              "1200     test  plastic   plastic93   plastic93.jpg   plastic/plastic93.jpg   \n",
              "1201     test  plastic   plastic95   plastic95.jpg   plastic/plastic95.jpg   \n",
              "1202     test  plastic   plastic98   plastic98.jpg   plastic/plastic98.jpg   \n",
              "\n",
              "      label  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "...     ...  \n",
              "1198      6  \n",
              "1199      6  \n",
              "1200      6  \n",
              "1201      6  \n",
              "1202      6  \n",
              "\n",
              "[1203 rows x 6 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conjunto</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery101</td>\n      <td>battery101.jpg</td>\n      <td>battery/battery101.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery108</td>\n      <td>battery108.jpg</td>\n      <td>battery/battery108.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery122</td>\n      <td>battery122.jpg</td>\n      <td>battery/battery122.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery132</td>\n      <td>battery132.jpg</td>\n      <td>battery/battery132.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery14</td>\n      <td>battery14.jpg</td>\n      <td>battery/battery14.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic864</td>\n      <td>plastic864.jpg</td>\n      <td>plastic/plastic864.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic90</td>\n      <td>plastic90.jpg</td>\n      <td>plastic/plastic90.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1200</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic93</td>\n      <td>plastic93.jpg</td>\n      <td>plastic/plastic93.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic95</td>\n      <td>plastic95.jpg</td>\n      <td>plastic/plastic95.jpg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic98</td>\n      <td>plastic98.jpg</td>\n      <td>plastic/plastic98.jpg</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1203 rows Ã— 6 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLlVPclyIBZj"
      },
      "source": [
        "path_path_2 = src_path + os.sep + \"data\" + os.sep + \"test\"  +  os.sep\n",
        "path_path_2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Mary\\\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\Machine_Learning_project\\\\data\\\\test\\\\'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1myTkKYIXIO"
      },
      "source": [
        "imagenes = []\n",
        "for i in test_set.path:\n",
        "    x = path_path_2 + i\n",
        "    imagenes_rs = cv2.imread(x, 1)\n",
        "    imagenes.append(cv2.resize(imagenes_rs, (224, 224)))\n",
        "    \n",
        "test_set[\"nombre_img\"] = imagenes"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lHLlbr1VX8l"
      },
      "source": [
        "test_set"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     conjunto     name          id             img                    path  \\\n",
              "0        test  battery  battery101  battery101.jpg  battery/battery101.jpg   \n",
              "1        test  battery  battery108  battery108.jpg  battery/battery108.jpg   \n",
              "2        test  battery  battery122  battery122.jpg  battery/battery122.jpg   \n",
              "3        test  battery  battery132  battery132.jpg  battery/battery132.jpg   \n",
              "4        test  battery   battery14   battery14.jpg   battery/battery14.jpg   \n",
              "...       ...      ...         ...             ...                     ...   \n",
              "1198     test  plastic  plastic864  plastic864.jpg  plastic/plastic864.jpg   \n",
              "1199     test  plastic   plastic90   plastic90.jpg   plastic/plastic90.jpg   \n",
              "1200     test  plastic   plastic93   plastic93.jpg   plastic/plastic93.jpg   \n",
              "1201     test  plastic   plastic95   plastic95.jpg   plastic/plastic95.jpg   \n",
              "1202     test  plastic   plastic98   plastic98.jpg   plastic/plastic98.jpg   \n",
              "\n",
              "      label                                         nombre_img  \n",
              "0         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
              "1         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
              "2         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
              "3         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
              "4         0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n",
              "...     ...                                                ...  \n",
              "1198      6  [[[182, 191, 200], [185, 194, 203], [184, 192,...  \n",
              "1199      6  [[[200, 221, 236], [200, 221, 236], [200, 221,...  \n",
              "1200      6  [[[216, 203, 201], [215, 202, 200], [214, 201,...  \n",
              "1201      6  [[[255, 242, 240], [255, 242, 240], [255, 242,...  \n",
              "1202      6  [[[223, 210, 208], [222, 209, 207], [221, 208,...  \n",
              "\n",
              "[1203 rows x 7 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conjunto</th>\n      <th>name</th>\n      <th>id</th>\n      <th>img</th>\n      <th>path</th>\n      <th>label</th>\n      <th>nombre_img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery101</td>\n      <td>battery101.jpg</td>\n      <td>battery/battery101.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery108</td>\n      <td>battery108.jpg</td>\n      <td>battery/battery108.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery122</td>\n      <td>battery122.jpg</td>\n      <td>battery/battery122.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery132</td>\n      <td>battery132.jpg</td>\n      <td>battery/battery132.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test</td>\n      <td>battery</td>\n      <td>battery14</td>\n      <td>battery14.jpg</td>\n      <td>battery/battery14.jpg</td>\n      <td>0</td>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic864</td>\n      <td>plastic864.jpg</td>\n      <td>plastic/plastic864.jpg</td>\n      <td>6</td>\n      <td>[[[182, 191, 200], [185, 194, 203], [184, 192,...</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic90</td>\n      <td>plastic90.jpg</td>\n      <td>plastic/plastic90.jpg</td>\n      <td>6</td>\n      <td>[[[200, 221, 236], [200, 221, 236], [200, 221,...</td>\n    </tr>\n    <tr>\n      <th>1200</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic93</td>\n      <td>plastic93.jpg</td>\n      <td>plastic/plastic93.jpg</td>\n      <td>6</td>\n      <td>[[[216, 203, 201], [215, 202, 200], [214, 201,...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic95</td>\n      <td>plastic95.jpg</td>\n      <td>plastic/plastic95.jpg</td>\n      <td>6</td>\n      <td>[[[255, 242, 240], [255, 242, 240], [255, 242,...</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>test</td>\n      <td>plastic</td>\n      <td>plastic98</td>\n      <td>plastic98.jpg</td>\n      <td>plastic/plastic98.jpg</td>\n      <td>6</td>\n      <td>[[[223, 210, 208], [222, 209, 207], [221, 208,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1203 rows Ã— 7 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAE5ADhqVbSn"
      },
      "source": [
        "DEFINIR X & Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJRy3dtZpG1V"
      },
      "source": [
        "X_train = np.stack(np.array(train_set[\"nombre_img\"]))\n",
        "y_train = np.array(train_set[\"label\"])\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4803, 224, 224, 3)\n(4803,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkHeHthWVMNp"
      },
      "source": [
        "X_test = np.stack(np.array(test_set[\"nombre_img\"]))\n",
        "y_test = np.array(test_set[\"label\"])\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1203, 224, 224, 3)\n(1203,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfGYaMFJpXa1"
      },
      "source": [
        "RESHAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4H7OsNIVvY_"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJQwHsAppHir"
      },
      "source": [
        "\n",
        "\n",
        "X_train = X_train.reshape(4803, 224, 224, 3)\n",
        "X_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4803, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B-eMHcNqFen"
      },
      "source": [
        "y_train = y_train.reshape(4803, 1)\n",
        "y_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4803, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTRNWjOPCwcC"
      },
      "source": [
        "# Reserve 10,000 samples for validation\n",
        "X_val = X_train[-900:]\n",
        "y_val = y_train[-900:]\n",
        "X_train = X_train[:-900]\n",
        "y_train = y_train[:-900]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntI_SbUyCwOR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGWDFu-RVw84"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFNmV2WpVyfl"
      },
      "source": [
        "X_test = X_test.reshape(1203, 224, 224, 3)\n",
        "X_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1203, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMxc3I1VyF2"
      },
      "source": [
        "y_test = y_test.reshape(1203,1)\n",
        "y_test.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1203, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJsENM7gIba0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FMj1rapGvk"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCZLVPRopGpC"
      },
      "source": [
        "datagen.fit(X_train)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMGuwdiWKlm"
      },
      "source": [
        "datagen.fit(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmphrJZaDpxD"
      },
      "source": [
        "datagen.fit(X_val)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxmjDneprvQ"
      },
      "source": [
        "ENTRENAR EL MODELO BASICO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WskAABKWpGhK"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(224, 224 ,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZdLvEG7p6vz",
        "outputId": "82f60c2e-a1f3-452d-9231-41800b2662f9"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 112, 112, 64)      256       \n_________________________________________________________________\ndropout (Dropout)            (None, 112, 112, 64)      0         \n_________________________________________________________________\nflatten (Flatten)            (None, 802816)            0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               102760576 \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 903       \n=================================================================\nTotal params: 102,800,455\nTrainable params: 102,800,327\nNon-trainable params: 128\n_________________________________________________________________\nNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgp6M2XRp2q6"
      },
      "source": [
        "COMPILAR EL MODELO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCgV2-SQpGXj"
      },
      "source": [
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model on training data\n",
            "Epoch 1/10\n",
            "61/61 [==============================] - 830s 13s/step - loss: 21.3220 - accuracy: 0.3464 - val_loss: 1354.1324 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 805s 13s/step - loss: 1.7769 - accuracy: 0.3059 - val_loss: 251.0861 - val_accuracy: 0.0022\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 543s 9s/step - loss: 1.5202 - accuracy: 0.4028 - val_loss: 53.8479 - val_accuracy: 0.0078\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 618s 10s/step - loss: 1.4309 - accuracy: 0.4522 - val_loss: 77.4831 - val_accuracy: 0.1400\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 687s 11s/step - loss: 1.5066 - accuracy: 0.4543 - val_loss: 40.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 620s 10s/step - loss: 1.3970 - accuracy: 0.4491 - val_loss: 774.2455 - val_accuracy: 0.2256\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 628s 10s/step - loss: 1.3089 - accuracy: 0.4924 - val_loss: 32.5386 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 619s 10s/step - loss: 1.2127 - accuracy: 0.5468 - val_loss: 16.3692 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 593s 10s/step - loss: 1.0719 - accuracy: 0.5875 - val_loss: 8.9104 - val_accuracy: 0.0178\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 698s 11s/step - loss: 1.0455 - accuracy: 0.6026 - val_loss: 5.9472 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TAwqF2c_H-S",
        "outputId": "2cc7533e-f8b5-4fbb-acc2-35d175fd4b9b"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 37s 985ms/step - loss: 2.1864 - accuracy: 0.3791\n",
            "\n",
            "Test accuracy: 0.37905237078666687 \n",
            "Loss: 2.186438798904419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYbFW5tq5SfK"
      },
      "source": [
        "model.save(\"baseline_model.h5\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# volverlo a cargar\n",
        "\n",
        "model = tf.keras.models.load_model('baseline_model.h5')"
      ]
    },
    {
      "source": [
        "## 2do modelo"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-WvticG5IN6"
      },
      "source": [
        "AUMENTAR REDES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCjMPstN5Df6"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Conv2D(64, (3, 3), input_shape=(224, 224 ,3), padding='same', activation='relu'))\n",
        "model_2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(256, activation='relu'))\n",
        "model_2.add(Dense(8, activation='softmax'))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmAip1T95DUW"
      },
      "source": [
        "\n",
        "\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model_2 on training data\n",
            "Epoch 1/20\n",
            "61/61 [==============================] - 849s 14s/step - loss: 12.7625 - accuracy: 0.5152 - val_loss: 124.3385 - val_accuracy: 0.0111\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 855s 14s/step - loss: 0.8202 - accuracy: 0.7028 - val_loss: 24.7818 - val_accuracy: 0.1700\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 861s 14s/step - loss: 0.5372 - accuracy: 0.8104 - val_loss: 22.2010 - val_accuracy: 0.1289\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 844s 14s/step - loss: 0.3616 - accuracy: 0.8709 - val_loss: 21.6939 - val_accuracy: 0.0878\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 845s 14s/step - loss: 0.2429 - accuracy: 0.9131 - val_loss: 22.0624 - val_accuracy: 0.1667\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 840s 14s/step - loss: 0.1242 - accuracy: 0.9613 - val_loss: 25.9192 - val_accuracy: 0.1044\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 842s 14s/step - loss: 0.0811 - accuracy: 0.9762 - val_loss: 30.5936 - val_accuracy: 0.0756\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 830s 14s/step - loss: 0.0672 - accuracy: 0.9823 - val_loss: 30.6178 - val_accuracy: 0.1133\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 833s 14s/step - loss: 0.0315 - accuracy: 0.9941 - val_loss: 34.2639 - val_accuracy: 0.1578\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 833s 14s/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 37.3203 - val_accuracy: 0.1322\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 836s 14s/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 45.3892 - val_accuracy: 0.1700\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 841s 14s/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 39.7282 - val_accuracy: 0.1944\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 839s 14s/step - loss: 0.0352 - accuracy: 0.9918 - val_loss: 95.3082 - val_accuracy: 0.0256\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 837s 14s/step - loss: 0.0973 - accuracy: 0.9690 - val_loss: 29.4902 - val_accuracy: 0.1778\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 839s 14s/step - loss: 0.0667 - accuracy: 0.9798 - val_loss: 34.6205 - val_accuracy: 0.1489\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 844s 14s/step - loss: 0.0859 - accuracy: 0.9726 - val_loss: 52.0244 - val_accuracy: 0.1522\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 835s 14s/step - loss: 0.0542 - accuracy: 0.9844 - val_loss: 47.5544 - val_accuracy: 0.1744\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 844s 14s/step - loss: 0.2669 - accuracy: 0.9462 - val_loss: 270.6943 - val_accuracy: 0.1844\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 838s 14s/step - loss: 0.1816 - accuracy: 0.9485 - val_loss: 40.7469 - val_accuracy: 0.1478\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 831s 14s/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 48.8305 - val_accuracy: 0.1389\n"
          ]
        }
      ],
      "source": [
        "print(\"Fit model_2 on training data\")\n",
        "history = model_2.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=20, verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 44s 1s/step - loss: 15.5935 - accuracy: 0.3026\n",
            "\n",
            "Test accuracy: 0.3025768995285034 \n",
            "Loss: 15.593498229980469\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model_2.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CDlbVO-EpBr"
      },
      "source": [
        "model_2.save(\"model_2.h5\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# En este modelo, resulta que la exactitud sobre el set de datos es mucho menor que la exactitud sobre el set de entrenamiento. Esta diferencia entre el train y el test se debe a overfitting. Sobre ajuste sucede cuando un modelo de aprendizaje de maquina tiene un rendimiento peor sobre un set de datos nuevo, que nunca antes ha visto comparada con el de entrenamiento. \n",
        "# Es por ello que a partir del ultimo modelo, se realizara un data augmentation y asÃ­ volver a entrenar y mejorar el score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTCuGJLSEp5b"
      },
      "source": [
        "Guardar segundo modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfDMJyRg-i1_",
        "outputId": "566cb9b5-c7bf-42ab-be53-328cbbe60a9d"
      },
      "source": [
        "train_loss, train_acc = model_2.evaluate(X_train,  y_train, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154/154 [==============================] - 9s 60ms/step - loss: 4.1263 - accuracy: 0.3632\n",
            "\n",
            "Test accuracy: 0.3631921708583832 \n",
            "Loss: 4.126265048980713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbk4U5PEECli"
      },
      "source": [
        "More Convultion Layers"
      ]
    },
    {
      "source": [
        "menos epocas "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# volverlo a cargar\n",
        "\n",
        "model_3 = tf.keras.models.load_model('model_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUVd1Ry5D_F7"
      },
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Conv2D(64, (3, 3), input_shape=(224, 224 ,3), padding='same', activation='relu'))\n",
        "model_3.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Dropout(0.25))\n",
        "\n",
        "model_3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Dropout(0.25))\n",
        "\n",
        "model_3.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model_3.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Dropout(0.25))\n",
        "\n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(1024, activation='relu'))\n",
        "model_3.add(Dense(8, activation='softmax'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMIVHdSnD-7K",
        "outputId": "1f1fc60b-0e24-4857-ba4d-9afddefaa9d1"
      },
      "source": [
        "print(model_3.summary())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_8 (Conv2D)            (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 112, 112, 64)      0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 112, 112, 64)      256       \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 112, 112, 128)     147584    \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 56, 56, 128)       0         \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 56, 56, 128)       512       \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 56, 56, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 28, 28, 256)       0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 28, 28, 256)       1024      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 28, 28, 256)       0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 200704)            0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1024)              205521920 \n_________________________________________________________________\ndense_5 (Dense)              (None, 8)                 8200      \n=================================================================\nTotal params: 206,677,320\nTrainable params: 206,676,424\nNon-trainable params: 896\n_________________________________________________________________\nNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9vwd31bFpXS"
      },
      "source": [
        "\n",
        "\n",
        "model_3.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model_2 on training data\n",
            "Epoch 1/10\n",
            "61/61 [==============================] - 1157s 19s/step - loss: 14.5630 - accuracy: 0.5045 - val_loss: 970.6505 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 1136s 19s/step - loss: 1.0920 - accuracy: 0.6367 - val_loss: 141.3829 - val_accuracy: 0.0056\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 1147s 19s/step - loss: 0.7858 - accuracy: 0.7153 - val_loss: 35.2252 - val_accuracy: 0.0633\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 1177s 19s/step - loss: 0.6733 - accuracy: 0.7504 - val_loss: 16.9968 - val_accuracy: 0.1944\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 1131s 19s/step - loss: 0.5252 - accuracy: 0.8081 - val_loss: 18.7693 - val_accuracy: 0.1767\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 1131s 19s/step - loss: 0.4256 - accuracy: 0.8450 - val_loss: 35.7228 - val_accuracy: 0.0422\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 1129s 19s/step - loss: 0.3678 - accuracy: 0.8665 - val_loss: 29.3005 - val_accuracy: 0.0467\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 1131s 19s/step - loss: 0.2643 - accuracy: 0.9026 - val_loss: 16.8536 - val_accuracy: 0.1822\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 1152s 19s/step - loss: 0.1995 - accuracy: 0.9288 - val_loss: 29.6325 - val_accuracy: 0.0567\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 1181s 19s/step - loss: 0.1487 - accuracy: 0.9449 - val_loss: 33.6089 - val_accuracy: 0.0489\n"
          ]
        }
      ],
      "source": [
        "print(\"Fit model_3 on training data\")\n",
        "history = model_3.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122/122 [==============================] - 221s 2s/step - loss: 2.3830 - accuracy: 0.7107\n",
            "\n",
            "Test accuracy: 0.3025768995285034 \n",
            "Loss: 15.593498229980469\n"
          ]
        }
      ],
      "source": [
        "train_loss, train_acc = model_3.evaluate(X_train,  y_train, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 68s 2s/step - loss: 9.7165 - accuracy: 0.4106\n",
            "\n",
            "Test accuracy: 0.41064006090164185 \n",
            "Loss: 9.716455459594727\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model_3.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FHT1SCWOf4f"
      },
      "source": [
        "Con este accuracy se procede a guardar el modelo como el mejor de esta prueba "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-rawFCMHsT"
      },
      "source": [
        "model.save(\"model_3_best.h5\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_J-xwJ3FfUc"
      },
      "source": [
        "Descargar el otro modelo bÃ¡sico "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK99SwxoOvt8"
      },
      "source": [
        "files.download(\"model_3_best.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT49yKUPBMw7"
      },
      "source": [
        "\n",
        "Data augmentation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8s6FW1KCd3X"
      },
      "source": [
        "\n",
        "There are 5 main techniques for image data augmentation:\n",
        "\n",
        "Image shifts\n",
        "Image flips\n",
        "Image rotations\n",
        "Image brightness\n",
        "Image zoom\n",
        "Since most of the images are well centered and cropped, it doesn't make sense using shifts or zoom, so we are going to keep it to horizontal flips, rotations between -25Âº and +25Âº and brightness.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WgQ_iulCh1y"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator=ImageDataGenerator(rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_model3 = src_path + os.sep + \"models\" + os.sep "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_data_augmentation = tf.keras.models.load_model(path_model3 + 'model_3_best.h5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lKAeRekDwgL"
      },
      "source": [
        "data_generator.fit(X_train)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMm2lF14DwU7"
      },
      "source": [
        "model_data_augmentation.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model_data_augmentation on training data\n",
            "Epoch 1/10\n",
            "61/61 [==============================] - 638s 10s/step - loss: 1.3550 - accuracy: 0.5165 - val_loss: 164.7543 - val_accuracy: 0.1900\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 607s 10s/step - loss: 1.5895 - accuracy: 0.4158 - val_loss: 556.6712 - val_accuracy: 0.0011\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 595s 10s/step - loss: 1.4463 - accuracy: 0.4497 - val_loss: 77.6210 - val_accuracy: 0.0144\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 625s 10s/step - loss: 1.4867 - accuracy: 0.4415 - val_loss: 23.5270 - val_accuracy: 0.2056\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 658s 11s/step - loss: 1.2266 - accuracy: 0.4876 - val_loss: 10.5378 - val_accuracy: 0.2089\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 608s 10s/step - loss: 1.1992 - accuracy: 0.4955 - val_loss: 3.9146 - val_accuracy: 0.2078\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 570s 9s/step - loss: 1.1146 - accuracy: 0.5237 - val_loss: 5.4690 - val_accuracy: 0.1700\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 578s 9s/step - loss: 1.0536 - accuracy: 0.5352 - val_loss: 8.3686 - val_accuracy: 0.1544\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 573s 9s/step - loss: 1.0793 - accuracy: 0.5486 - val_loss: 33.8669 - val_accuracy: 0.0111\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 568s 9s/step - loss: 1.0333 - accuracy: 0.5557 - val_loss: 14.2158 - val_accuracy: 0.1633\n"
          ]
        }
      ],
      "source": [
        "print(\"Fit model_data_augmentation on training data\")\n",
        "history = model_data_augmentation.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 43s 1s/step - loss: 3.5095 - accuracy: 0.3084\n",
            "\n",
            "Test accuracy: 0.3083956837654114 \n",
            "Loss: 3.50949764251709\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model_data_augmentation.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#guardar este modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_model = src_path + os.sep + \"models\" + os.sep "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_data_augmentation.save(path_model + \"model_data_augmentation.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# se procede a entrenar este modelo con mas redes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rotaciÃ³n de imagenes con una rotaciÃ³n aleatoria para ver si se mejora el accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_generator=ImageDataGenerator(brightness_range=[0.2,1.0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_generator.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_data_augmentation_ran = tf.keras.models.load_model(path_model3 + 'model_data_augmentation.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_data_augmentation_ran.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model_data_augmentation on training data\n",
            "Epoch 1/10\n",
            "61/61 [==============================] - 566s 9s/step - loss: 1.0489 - accuracy: 0.5516 - val_loss: 42.0274 - val_accuracy: 0.1900\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 582s 10s/step - loss: 0.9292 - accuracy: 0.5824 - val_loss: 435.2493 - val_accuracy: 0.2222\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 591s 10s/step - loss: 0.9897 - accuracy: 0.5890 - val_loss: 69.4559 - val_accuracy: 0.1944\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 580s 10s/step - loss: 0.8925 - accuracy: 0.6057 - val_loss: 24.7287 - val_accuracy: 0.0478\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 600s 10s/step - loss: 1.0800 - accuracy: 0.5562 - val_loss: 388.0945 - val_accuracy: 0.0633\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 601s 10s/step - loss: 0.8935 - accuracy: 0.6139 - val_loss: 38.0887 - val_accuracy: 0.0078\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 604s 10s/step - loss: 0.8676 - accuracy: 0.6531 - val_loss: 9.4197 - val_accuracy: 0.0011\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 655s 11s/step - loss: 0.8155 - accuracy: 0.6708 - val_loss: 38.9387 - val_accuracy: 0.0078\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 614s 10s/step - loss: 0.9779 - accuracy: 0.6103 - val_loss: 517.0087 - val_accuracy: 0.0189\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 601s 10s/step - loss: 0.8406 - accuracy: 0.6562 - val_loss: 30.1542 - val_accuracy: 0.0033\n"
          ]
        }
      ],
      "source": [
        "print(\"Fit model_data_augmentation on training data\")\n",
        "history = model_data_augmentation_ran.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_data_augmentation_ran.save(path_model + \"model_data_augmentation_rot_alea.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 37s 959ms/step - loss: 3.5095 - accuracy: 0.3084\n",
            "\n",
            "Test accuracy: 0.3083956837654114 \n",
            "Loss: 3.50949764251709\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model_data_augmentation.evaluate(X_test,  y_test, verbose=1)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc, \"\\nLoss:\", test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Este accuracy ha dado peores resultados que el resto de los modelos entrenados "
      ]
    }
  ]
}