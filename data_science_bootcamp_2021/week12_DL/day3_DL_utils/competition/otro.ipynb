{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "a9b83ec4160fc914f5169c2fc0bc9ab1c02e189a457abfa966969b692f6336e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images_path = \"C:\\\\Users\\\\Mary\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\week12_DL\\\\day3_DL_utils\\\\competition\\\\train\"\n",
    "\n",
    "train_labels_path = (\"train_set.csv\") # direct path to the csv-file\n",
    "\n",
    "test_images_path = \"C:\\\\Users\\\\Mary\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\week12_DL\\\\day3_DL_utils\\\\competition\\\\train\"\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label  id_img             path\n",
       "0  happy   22373  happy/22373.jpg\n",
       "1  happy   21433  happy/21433.jpg\n",
       "2  happy   12418  happy/12418.jpg\n",
       "3  happy   21278  happy/21278.jpg\n",
       "4  happy    8081  happy/08081.jpg"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>id_img</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>happy</td>\n      <td>22373</td>\n      <td>happy/22373.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>happy</td>\n      <td>21433</td>\n      <td>happy/21433.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>12418</td>\n      <td>happy/12418.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy</td>\n      <td>21278</td>\n      <td>happy/21278.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>happy</td>\n      <td>8081</td>\n      <td>happy/08081.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df = pd.read_csv(train_labels_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'image_data_generator' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-874df617062a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m img_gen = image_data_generator(\n\u001b[0m\u001b[0;32m      2\u001b[0m   rescale = 1/255)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "img_gen = image_data_generator(\n",
    "  rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator <- flow_images_from_dataframe(\n",
    "  dataframe = labels_df, \n",
    "  directory = img_path,\n",
    "  x_col = \"Id\", \n",
    "  y_col = \"label\",\n",
    "  generator = img_gen, \n",
    "  subset = \"training\",\n",
    "  target_size = c(224, 224), color_mode = \"rgb\",\n",
    "  batch_size = 10\n",
    ") \n",
    "\n",
    "validation_generator <- flow_images_from_dataframe(\n",
    "  dataframe = labels_df, \n",
    "  directory = img_path,\n",
    "  x_col = \"id_img\", \n",
    "  y_col = \"Expected\",\n",
    "  generator = image_data_generator(rescale = 1/255, \n",
    "                                   validation_split = .2), # img_gen, \n",
    "  subset = \"validation\",\n",
    "  target_size = c(224, 224), color_mode = \"rgb\",\n",
    "  batch_size = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "image_dataset_from_directory() got an unexpected keyword argument 'x_col'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-68632ba90841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m   batch_size=batch_size)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
      "\u001b[1;31mTypeError\u001b[0m: image_dataset_from_directory() got an unexpected keyword argument 'x_col'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\Mary\\Desktop\\\\BootCamp\\\\Python\\\\MaryC-MezaR\\\\data_science_bootcamp_2021\\\\week12_DL\\\\day3_DL_utils\\\\competition\\\\train\"\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  x_col = \"id_img\", \n",
    "  y_col = \"label\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  x_col = \"Id\", \n",
    "  y_col = \"Label\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 48, 48, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (img_height, img_height, 3),\n",
    "                  include_top=False, \n",
    "                  weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    " \n",
    "\n",
    "x0 = layers.Flatten()(base_model.output) \n",
    "x1 = layers.Dense(512, activation='relu')(x0) \n",
    "x2 = layers.Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x3 = layers.Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x3) #aqui ya estoy concatenando los modelos\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/7\n",
      "155/155 [==============================] - 65s 410ms/step - loss: 3.5678 - acc: 0.6234 - val_loss: 1.6815 - val_acc: 0.6219\n",
      "Epoch 2/7\n",
      "155/155 [==============================] - 65s 419ms/step - loss: 1.1133 - acc: 0.6863 - val_loss: 0.8394 - val_acc: 0.7045\n",
      "Epoch 3/7\n",
      "155/155 [==============================] - 62s 397ms/step - loss: 0.6228 - acc: 0.7474 - val_loss: 0.7410 - val_acc: 0.7150\n",
      "Epoch 4/7\n",
      "155/155 [==============================] - 68s 435ms/step - loss: 0.5147 - acc: 0.7741 - val_loss: 0.7524 - val_acc: 0.7101\n",
      "Epoch 5/7\n",
      "155/155 [==============================] - 60s 388ms/step - loss: 0.4296 - acc: 0.8025 - val_loss: 0.7228 - val_acc: 0.7109\n",
      "Epoch 6/7\n",
      "155/155 [==============================] - 55s 354ms/step - loss: 0.3832 - acc: 0.8270 - val_loss: 0.7147 - val_acc: 0.7085\n",
      "Epoch 7/7\n",
      "155/155 [==============================] - 69s 447ms/step - loss: 0.3546 - acc: 0.8409 - val_loss: 0.7491 - val_acc: 0.7036\n"
     ]
    }
   ],
   "source": [
    "vgghist = model.fit(train_ds,\n",
    "                    validation_data = val_ds,\n",
    "                    epochs = 7,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}